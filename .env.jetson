# ============================================================================
# Jetson Nano Super 8GB - Fully Local Configuration
# ============================================================================
# This configuration optimizes the Reachy Mini Conversation App for edge
# deployment on Jetson Nano Super with 8GB RAM. All processing runs locally.
# ============================================================================

# FULL LOCAL MODE (always enabled - no cloud dependencies)
FULL_LOCAL_MODE=true
JETSON_OPTIMIZE=true

# ============================================================================
# LOCAL LLM CONFIGURATION (Ollama recommended for Jetson)
# ============================================================================
LLM_PROVIDER=ollama
OLLAMA_ENDPOINT=http://localhost:11434/v1

# Recommended models for Jetson Nano Super 8GB (choose one):
# - gemma3:1b: 1B params, ~1GB RAM (fast, less accurate)
# - gemma3:4b: 4B params, ~4GB RAM (slower, more accurate)
OLLAMA_MODEL=gemma3:1b

# Alternative: LM Studio (uncomment to use instead of Ollama)
# LLM_PROVIDER=lmstudio
# LMSTUDIO_ENDPOINT=http://localhost:1234/v1
# LMSTUDIO_MODEL=Phi-3-mini-4k-instruct.Q4_K_M.gguf

# ============================================================================
# SPEECH-TO-TEXT (Distil-Whisper - optimized for edge)
# ============================================================================
# Model options:
# - distil-whisper/distil-small.en: Fastest, English-only (recommended)
# - distil-whisper/distil-medium.en: Better accuracy, slower
# - distil-whisper/distil-large-v3: Best quality, heaviest
DISTIL_WHISPER_MODEL=distil-whisper/distil-small.en
WHISPER_LANGUAGE=en

# ============================================================================
# TEXT-TO-SPEECH (Kokoro via FastRTC - lightweight neural TTS)
# ============================================================================
# Kokoro (82M parameters) via FastRTC built-in support

# Voice options:
# - af_sarah: American Female (Sarah)
# - am_michael: American Male (Michael)
# - bf_emma: British Female (Emma)
# - bm_lewis: British Male (Lewis)
KOKORO_VOICE=af_sarah

# Speech speed (0.5-2.0, default 1.0)
KOKORO_SPEED=1.0

# ============================================================================
# VOICE ACTIVITY DETECTION (Built-in energy-based VAD)
# ============================================================================
VAD_ENERGY_THRESHOLD=0.05
VAD_SILENCE_DURATION=0.8
VAD_MIN_SPEECH_DURATION=0.3

# ============================================================================
# ONNX RUNTIME OPTIMIZATION (Use CUDA on Jetson)
# ============================================================================
ONNX_PROVIDERS=CUDAExecutionProvider,CPUExecutionProvider

# ============================================================================
# VISION CONFIGURATION (Optional - for camera tools)
# ============================================================================
HF_HOME=/mnt/storage/hf_cache  # Use external storage if available
LOCAL_VISION_MODEL=HuggingFaceTB/SmolVLM2-2.2B-Instruct
# HF_TOKEN=your_token_here  # Optional, only if needed for gated models

# ============================================================================
# MEMORY MANAGEMENT (Important for 8GB device)
# ============================================================================
# Set PYTORCH_CUDA_ALLOC_CONF for better memory management
# PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512

# ============================================================================
# CUSTOM PROFILE (Optional - personality customization)
# ============================================================================
# REACHY_MINI_CUSTOM_PROFILE=friendly_assistant

# ============================================================================
# NOTES FOR JETSON DEPLOYMENT
# ============================================================================
# 1. Install Ollama: curl -fsSL https://ollama.com/install.sh | sh
# 2. Pull model: ollama pull phi-3-mini-4k-instruct
# 3. Install JetPack if not present: sudo apt-get install nvidia-jetpack
# 4. Monitor resources: tegrastats
# 5. Expected memory usage: ~3-4GB peak (leaves 4GB for system)
# 6. Expected latency: <3s end-to-end for typical queries
#
# To install the app with Jetson optimizations:
#   pip install -e ".[jetson,all_vision]"
#
# To run in console mode (headless):
#   reachy-mini-conversation-app
#
# To run with Gradio UI:
#   reachy-mini-conversation-app --gradio
